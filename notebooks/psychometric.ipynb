{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:27:09.987217Z",
     "start_time": "2018-09-18T16:27:09.111643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import morphs\n",
    "import behav\n",
    "from behav import loading\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:28:35.895274Z",
     "start_time": "2018-09-18T16:27:09.993797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2818: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2818: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "data_folder = '/mnt/cube/RawData/Zog/'\n",
    "behav_data = loading.load_data_pandas(morphs.subj.BEHAVE_SUBJS, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:28:35.910478Z",
     "start_time": "2018-09-18T16:28:35.900874Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_behav_data_stim_id(df):\n",
    "    df = df[(df['response'] != 'none') & (df['type_'] == 'normal')]\n",
    "    df['stim_id'] = df['stimulus'].str.split('/').str[-1].str[:-4]\n",
    "    df = df[df['stim_id'].str.len() == 5]\n",
    "    df = df[df['stim_id'].str[1:] != '_rec']\n",
    "    df['subj'] = subj\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:19.453011Z",
     "start_time": "2018-09-18T16:28:35.915288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cumulative_data = pd.concat([parse_behav_data_stim_id(behav_data[subj]) for subj in morphs.subj.BEHAVE_SUBJS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:19.469100Z",
     "start_time": "2018-09-18T16:29:19.457631Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_behave_data(df):\n",
    "    df = df[['class_', 'response', 'correct', 'rt', 'reward', 'stim_id', 'subj']]\n",
    "    for col in ['correct', 'reward']:\n",
    "        df[col] = df[col].astype(bool)\n",
    "    for col in ['class_', 'response', 'subj']:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:22.698679Z",
     "start_time": "2018-09-18T16:29:19.473249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cumulative_data = reduce_behave_data(cumulative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:39.456266Z",
     "start_time": "2018-09-18T16:29:22.703995Z"
    }
   },
   "outputs": [],
   "source": [
    "morphs.data.parse.stim_id(cumulative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:39.472086Z",
     "start_time": "2018-09-18T16:29:39.461773Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_behav_data_inverted(df):\n",
    "    df['class_'] = df['class_'].astype(str)# apparently groupby with categorical dtype is broken\n",
    "    inverted_map = df[(df['morph_pos']==1)].groupby(['subj', 'morph_dim'], observed=True).agg(lambda x: x.iloc[0])['class_'] == 'R'\n",
    "    df = df.join(inverted_map.to_frame(name='inverted'), on=('subj', 'morph_dim'), how='left', sort=False)\n",
    "    df['greater_response'] = (df['response'] == 'R') != (df['inverted'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:42.778217Z",
     "start_time": "2018-09-18T16:29:39.476443Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulative_data = parse_behav_data_inverted(cumulative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:45.725599Z",
     "start_time": "2018-09-18T16:29:42.783505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subj\n",
       "B1082    1280159\n",
       "B1088     545599\n",
       "B1101     321631\n",
       "B1105    1486658\n",
       "B1107     111549\n",
       "B1218     449423\n",
       "B1222    1248989\n",
       "B979       68701\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_data.groupby('subj').agg('count')['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:29:45.741367Z",
     "start_time": "2018-09-18T16:29:45.731245Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_inverted(subj, morph_dim):\n",
    "    left, right = morphs.subj.TRAINING[subj].lower().split('|')\n",
    "    les, gre = morph_dim\n",
    "    assert (les in left) != (gre in left), (row, morphs.subj.TRAINING[row['subj']])\n",
    "    assert (les in right) != (gre in right), (row, morphs.subj.TRAINING[row['subj']])\n",
    "    return gre in left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:30:27.033430Z",
     "start_time": "2018-09-18T16:29:45.744420Z"
    }
   },
   "outputs": [],
   "source": [
    "for (subj, morph_dim), group in cumulative_data.groupby(['subj', 'morph_dim'], observed=True):\n",
    "    cumulative_data.loc[group.index, 'inverted_slow'] = is_inverted(subj, morph_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:30:27.126505Z",
     "start_time": "2018-09-18T16:30:27.038779Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(cumulative_data['inverted'] == cumulative_data['inverted_slow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:30:27.227935Z",
     "start_time": "2018-09-18T16:30:27.131814Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "\n",
    "eta_bounds = 1e-16\n",
    "\n",
    "def four_param_logistic(p):\n",
    "    \"\"\"4p logistic function maker.\n",
    "    \n",
    "    Returns a function that accepts x and returns y for\n",
    "    the 4-parameter logistic defined by p.\n",
    "    \n",
    "    The 4p logistic is defined by:\n",
    "    y = A + (K - A) / (1 + exp(-B*(x-M)))\n",
    "    \n",
    "    Args:\n",
    "        p: an iterable of length 4\n",
    "            A, K, B, M = p\n",
    "    \n",
    "    Returns:\n",
    "        A function that accepts a numpy array as an argument \n",
    "        for x values and returns the y values for the defined 4pl curve.\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    A, K, B, M = p\n",
    "    def f(x):\n",
    "        return A + (K - A) / (1 + np.exp(-B*(x-M)))\n",
    "    return f\n",
    "\n",
    "def ln_like(p, x, y):\n",
    "    \"\"\"log likelihood for fitting the four parameter logistic.\n",
    "    \n",
    "    Args:\n",
    "        p: an iterable of length 4\n",
    "            A, K, B, M = p\n",
    "        x: a numpy array of length n\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    \n",
    "    Returns:\n",
    "        The log-likelihood that the samples y are drawn from a distribution\n",
    "        where the 4pl(x; p) is the probability of getting y=1\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    p_4pl = four_param_logistic(p)\n",
    "    probs = p_4pl(x)\n",
    "    return np.sum(y * np.log(probs) + (1 - y) * np.log(1 - probs))\n",
    "\n",
    "def dln_like(p, x, y):\n",
    "    \"\"\"gradient of the log likelihood for fitting the four parameter logistic.\n",
    "    \n",
    "    Args:\n",
    "        p: an iterable of length 4\n",
    "            A, K, B, M = p\n",
    "        x: a numpy array of length n\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    \n",
    "    Returns:\n",
    "        The gradient of the log-likelihood that the samples y are drawn from \n",
    "        a distribution where the 4pl(x; p) is the probability of getting y=1\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    A, K, B, M = p\n",
    "    def f(x):\n",
    "        return A + (K - A) / (1 + np.exp(-B*(x-M)))\n",
    "    def df(x):\n",
    "        temp1 = np.exp(-B*(x-M))\n",
    "        dK = 1. / (1. + temp1)\n",
    "        dA = 1. - dK\n",
    "        temp2 = temp1 / (1. + temp1) ** 2\n",
    "        dB = (K - A) * (x - M) * temp2\n",
    "        dM = -(K - A) * B * temp2\n",
    "        return np.vstack((dA, dK, dB, dM))\n",
    "    p_4pl = f(x)\n",
    "    d_p_4pl = df(x)\n",
    "    return np.sum(y * d_p_4pl / (p_4pl) - (1 - y) * d_p_4pl / (1 - p_4pl), 1)\n",
    "\n",
    "def nll(*args):\n",
    "    \"\"\"negative log-likelihood for fitting the 4 param logistic.\"\"\"\n",
    "    return -ln_like(*args)\n",
    "\n",
    "def ndll(*args):\n",
    "    \"\"\"negative grad of the log-likelihood for fitting the 4 param logistic.\"\"\"\n",
    "    return -dln_like(*args)\n",
    "\n",
    "def est_pstart(x, y):\n",
    "    \"\"\"basic estimation of a good place to start log likelihood maximization.\n",
    "    \n",
    "    Args:\n",
    "        x: a numpy array of length n\n",
    "            assumes a finite number of unique x values\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    \n",
    "    Returns:\n",
    "        p_start: an iterable of length 4 that should be a reasonable spot to\n",
    "            start the optimization\n",
    "            A, K, B, M = p_start\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    p_start = [.01, .99, .2, 0]\n",
    "    x_vals = np.unique(x)\n",
    "    p_start[3] = np.mean(x_vals)\n",
    "    y_est = np.array([np.mean(y[x==i]) for i in x_vals])\n",
    "    midpoint_est = np.mean(np.where((y_est[0:-1]<.5) & (y_est[1:]>=.5)))\n",
    "    if np.isnan(midpoint_est):\n",
    "        return p_start\n",
    "    p_start[3] = midpoint_est\n",
    "    return p_start\n",
    "\n",
    "def fit_4pl(x, y, p_start=None, verbose=False):\n",
    "    \"\"\"Fits a 4 parameter logistic function to the data.\n",
    "    \n",
    "    Args:\n",
    "        x: a numpy array of length n\n",
    "            assumes a finite number of unique x values\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    optional:\n",
    "        p_start: an iterable of length 4 that would be a reasonable spot to\n",
    "            start the optimization. If None, tries to estimate it.\n",
    "            A, K, B, M = p_start\n",
    "            default=None\n",
    "        verbose: boolean flag that allows printing of more error messages.\n",
    "    \n",
    "    Returns:\n",
    "        p_result: an iterable of length 4 that defines the model that \n",
    "        is maximally likely\n",
    "            A, K, B, M = p_result\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not p_start:\n",
    "            p_start = est_pstart(x, y)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    for i in range(3):\n",
    "        if verbose and i > 0:\n",
    "            print 'retry', i\n",
    "        result = op.minimize(nll, p_start, args=(x, y), jac=ndll, bounds=((eta_bounds,1-eta_bounds), (eta_bounds,1-eta_bounds), (None, None), (None, None)))\n",
    "        if result.success:\n",
    "            return result.x\n",
    "        else:\n",
    "            if verbose:\n",
    "                print p_start, 'failure', result\n",
    "            p_start = result.x\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T16:31:25.847820Z",
     "start_time": "2018-09-18T16:30:27.230235Z"
    }
   },
   "outputs": [],
   "source": [
    "psychometric_params = {}\n",
    "for subj, subj_group in cumulative_data.groupby('subj'):\n",
    "    psychometric_params[subj] = {}\n",
    "    for dim, dim_group in subj_group.groupby('morph_dim'):\n",
    "        x = dim_group['morph_pos'].astype(float).values\n",
    "        y = dim_group['greater_response'].astype(float).values\n",
    "        psychometric_params[subj][dim] = fit_4pl(x, y, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (morphs)",
   "language": "python",
   "name": "morphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
