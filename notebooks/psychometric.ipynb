{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T09:29:28.420978Z",
     "start_time": "2018-09-17T09:29:28.415466Z"
    }
   },
   "outputs": [],
   "source": [
    "import morphs\n",
    "import behav\n",
    "from behav import loading\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T09:11:57.125028Z",
     "start_time": "2018-09-17T09:10:07.721072Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2818: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2818: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "data_folder = '/mnt/cube/RawData/Zog/'\n",
    "behav_data = loading.load_data_pandas(morphs.subj.BEHAVE_SUBJS, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:37:08.091919Z",
     "start_time": "2018-09-17T23:37:08.078563Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_behav_data_stim_id(df):\n",
    "    df = df[(df['response'] != 'none') & (df['type_'] == 'normal')]\n",
    "    df['stim_id'] = df['stimulus'].str.split('/').str[-1].str[:-4]\n",
    "    df = df[df['stim_id'].str.len() == 5]\n",
    "    df = df[df['stim_id'].str[1:] != '_rec']\n",
    "    df['subj'] = subj\n",
    "    morphs.data.parse.stim_id(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:39:01.486642Z",
     "start_time": "2018-09-17T23:37:57.239822Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/morphs/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "cumulative_data = pd.concat([parse_behav_data_stim_id(behav_data[subj]) for subj in morphs.subj.BEHAVE_SUBJS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:39:01.501784Z",
     "start_time": "2018-09-17T23:39:01.492017Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_behav_data_inverted(df):\n",
    "    inverted_map = df[(df['morph_pos']==1)].groupby(['subj', 'morph_dim']).agg(lambda x: x.iloc[0])['class_'] == 'R'\n",
    "    df = df.join(inverted_map.to_frame(name='inverted'), on=('subj', 'morph_dim'), how='left', sort=False)\n",
    "    df['greater_response'] = (df['response'] == 'R') != (df['inverted'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:39:26.753646Z",
     "start_time": "2018-09-17T23:39:23.965285Z"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_data = parse_behav_data_inverted(cumulative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T09:34:10.888863Z",
     "start_time": "2018-09-17T09:34:06.389469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subj\n",
       "B1082    1280159\n",
       "B1088     545599\n",
       "B1101     321631\n",
       "B1105    1485138\n",
       "B1107     111549\n",
       "B1218     449423\n",
       "B1222    1248989\n",
       "B979       68701\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_data.groupby('subj').agg('count')['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:01:38.520402Z",
     "start_time": "2018-09-17T23:01:38.507706Z"
    }
   },
   "outputs": [],
   "source": [
    "del cumulative_data['inverted']\n",
    "del cumulative_data['greater_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T20:53:00.673736Z",
     "start_time": "2018-09-17T20:53:00.665831Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_inverted(subj, morph_dim):\n",
    "    left, right = morphs.subj.TRAINING[subj].lower().split('|')\n",
    "    les, gre = morph_dim\n",
    "    assert (les in left) != (gre in left), (row, morphs.subj.TRAINING[row['subj']])\n",
    "    assert (les in right) != (gre in right), (row, morphs.subj.TRAINING[row['subj']])\n",
    "    return gre in left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:40:41.103257Z",
     "start_time": "2018-09-17T23:39:56.212425Z"
    }
   },
   "outputs": [],
   "source": [
    "for (subj, morph_dim), group in cumulative_data.groupby(['subj', 'morph_dim']):\n",
    "    cumulative_data.loc[group.index, 'inverted_slow'] = is_inverted(subj, morph_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T23:59:56.506653Z",
     "start_time": "2018-09-17T23:59:56.415449Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(cumulative_data['inverted'] == cumulative_data['inverted_slow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T09:45:28.781959Z",
     "start_time": "2018-09-17T09:45:28.680732Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "\n",
    "eta_bounds = 1e-16\n",
    "\n",
    "def four_param_logistic(p):\n",
    "    \"\"\"4p logistic function maker.\n",
    "    \n",
    "    Returns a function that accepts x and returns y for\n",
    "    the 4-parameter logistic defined by p.\n",
    "    \n",
    "    The 4p logistic is defined by:\n",
    "    y = A + (K - A) / (1 + exp(-B*(x-M)))\n",
    "    \n",
    "    Args:\n",
    "        p: an iterable of length 4\n",
    "            A, K, B, M = p\n",
    "    \n",
    "    Returns:\n",
    "        A function that accepts a numpy array as an argument \n",
    "        for x values and returns the y values for the defined 4pl curve.\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    A, K, B, M = p\n",
    "    def f(x):\n",
    "        return A + (K - A) / (1 + np.exp(-B*(x-M)))\n",
    "    return f\n",
    "\n",
    "def ln_like(p, x, y):\n",
    "    \"\"\"log likelihood for fitting the four parameter logistic.\n",
    "    \n",
    "    Args:\n",
    "        p: an iterable of length 4\n",
    "            A, K, B, M = p\n",
    "        x: a numpy array of length n\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    \n",
    "    Returns:\n",
    "        The log-likelihood that the samples y are drawn from a distribution\n",
    "        where the 4pl(x; p) is the probability of getting y=1\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    p_4pl = four_param_logistic(p)\n",
    "    probs = p_4pl(x)\n",
    "    return np.sum(y * np.log(probs) + (1 - y) * np.log(1 - probs))\n",
    "\n",
    "def dln_like(p, x, y):\n",
    "    \"\"\"gradient of the log likelihood for fitting the four parameter logistic.\n",
    "    \n",
    "    Args:\n",
    "        p: an iterable of length 4\n",
    "            A, K, B, M = p\n",
    "        x: a numpy array of length n\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    \n",
    "    Returns:\n",
    "        The gradient of the log-likelihood that the samples y are drawn from \n",
    "        a distribution where the 4pl(x; p) is the probability of getting y=1\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    A, K, B, M = p\n",
    "    def f(x):\n",
    "        return A + (K - A) / (1 + np.exp(-B*(x-M)))\n",
    "    def df(x):\n",
    "        temp1 = np.exp(-B*(x-M))\n",
    "        dK = 1. / (1. + temp1)\n",
    "        dA = 1. - dK\n",
    "        temp2 = temp1 / (1. + temp1) ** 2\n",
    "        dB = (K - A) * (x - M) * temp2\n",
    "        dM = -(K - A) * B * temp2\n",
    "        return np.vstack((dA, dK, dB, dM))\n",
    "    p_4pl = f(x)\n",
    "    d_p_4pl = df(x)\n",
    "    return np.sum(y * d_p_4pl / (p_4pl) - (1 - y) * d_p_4pl / (1 - p_4pl), 1)\n",
    "\n",
    "def nll(*args):\n",
    "    \"\"\"negative log-likelihood for fitting the 4 param logistic.\"\"\"\n",
    "    return -ln_like(*args)\n",
    "\n",
    "def ndll(*args):\n",
    "    \"\"\"negative grad of the log-likelihood for fitting the 4 param logistic.\"\"\"\n",
    "    return -dln_like(*args)\n",
    "\n",
    "def est_pstart(x, y):\n",
    "    \"\"\"basic estimation of a good place to start log likelihood maximization.\n",
    "    \n",
    "    Args:\n",
    "        x: a numpy array of length n\n",
    "            assumes a finite number of unique x values\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    \n",
    "    Returns:\n",
    "        p_start: an iterable of length 4 that should be a reasonable spot to\n",
    "            start the optimization\n",
    "            A, K, B, M = p_start\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    p_start = [.01, .99, .2, 0]\n",
    "    x_vals = np.unique(x)\n",
    "    p_start[3] = np.mean(x_vals)\n",
    "    y_est = np.array([np.mean(y[x==i]) for i in x_vals])\n",
    "    midpoint_est = np.mean(np.where((y_est[0:-1]<.5) & (y_est[1:]>=.5)))\n",
    "    if np.isnan(midpoint_est):\n",
    "        return p_start\n",
    "    p_start[3] = midpoint_est\n",
    "    return p_start\n",
    "\n",
    "def fit_4pl(x, y, p_start=None, verbose=False):\n",
    "    \"\"\"Fits a 4 parameter logistic function to the data.\n",
    "    \n",
    "    Args:\n",
    "        x: a numpy array of length n\n",
    "            assumes a finite number of unique x values\n",
    "        y: a numpy array of length n\n",
    "            must be of dtype double or float so multiplication works\n",
    "    optional:\n",
    "        p_start: an iterable of length 4 that would be a reasonable spot to\n",
    "            start the optimization. If None, tries to estimate it.\n",
    "            A, K, B, M = p_start\n",
    "            default=None\n",
    "        verbose: boolean flag that allows printing of more error messages.\n",
    "    \n",
    "    Returns:\n",
    "        p_result: an iterable of length 4 that defines the model that \n",
    "        is maximally likely\n",
    "            A, K, B, M = p_result\n",
    "            \n",
    "    Marvin Thielk 2016\n",
    "    mthielk@ucsd.edu\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not p_start:\n",
    "            p_start = est_pstart(x, y)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    for i in range(3):\n",
    "        if verbose and i > 0:\n",
    "            print 'retry', i\n",
    "        result = op.minimize(nll, p_start, args=(x, y), jac=ndll, bounds=((eta_bounds,1-eta_bounds), (eta_bounds,1-eta_bounds), (None, None), (None, None)))\n",
    "        if result.success:\n",
    "            return result.x\n",
    "        else:\n",
    "            if verbose:\n",
    "                print p_start, 'failure', result\n",
    "            p_start = result.x\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T10:11:47.227945Z",
     "start_time": "2018-09-17T10:10:47.151153Z"
    }
   },
   "outputs": [],
   "source": [
    "psychometric_params = {}\n",
    "for subj, subj_group in cumulative_data.groupby('subj'):\n",
    "    psychometric_params[subj] = {}\n",
    "    for dim, dim_group in subj_group.groupby('morph_dim'):\n",
    "        x = dim_group['morph_pos'].astype(float).values\n",
    "        y = dim_group['greater_response'].astype(float).values\n",
    "        psychometric_params[subj][dim] = fit_4pl(x, y, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (morphs)",
   "language": "python",
   "name": "morphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
